# AgentBench Jolt Analysis

This directory contains the implementation of the AgentBench analysis component for the Jolting Technologies Hypothesis paper. It provides tools for generating synthetic AgentBench leaderboard data and analyzing it to detect jolts (positive third derivatives) in AI agent performance.

## Overview

The AgentBench analysis examines monthly leaderboard data to identify periods of super-exponential acceleration in AI agent capabilities. The implementation uses synthetic data that mimics the expected structure and statistical properties of historical AgentBench data, with the ability to seamlessly transition to real historical data when it becomes available.

## Directory Structure

```
agentbench/
├── agentbench_jolt/           # Core Python package
│   ├── __init__.py            # Package initialization
│   ├── generator.py           # Synthetic data generation
│   └── analyzer.py            # Data preprocessing and jolt detection
├── data/                      # Data directory
│   └── synthetic_agentbench_data.csv  # Generated synthetic data
├── notebooks/                 # Jupyter notebooks
│   └── Figure_AgentBench.ipynb  # Analysis and visualization notebook
├── results/                   # Results directory
│   ├── figures/               # Generated figures
│   └── tables/                # LaTeX tables
└── run_agentbench_analysis.py  # Main script to run the analysis
```

## Components

### agentbench_jolt Package

The `agentbench_jolt` package provides the core functionality for the AgentBench analysis:

1. **generator.py**: Generates synthetic AgentBench leaderboard data with configurable parameters:
   - Monthly snapshots over a specified time period
   - Configurable growth rate and noise level
   - Optional jolt with adjustable timing, magnitude, and width
   - Multiple AI models with realistic performance distributions

2. **analyzer.py**: Analyzes AgentBench data to detect jolts:
   - Preprocesses data to extract performance metrics
   - Applies the hybrid jolt detection algorithm from the Monte Carlo module
   - Generates visualizations of performance trajectories and derivatives
   - Creates LaTeX-ready tables of results

### Main Script

The `run_agentbench_analysis.py` script provides a command-line interface to run the complete analysis pipeline:
1. Generate synthetic AgentBench data
2. Preprocess the data
3. Detect jolts using the hybrid detector
4. Create visualizations
5. Generate LaTeX tables

### Jupyter Notebook

The `Figure_AgentBench.ipynb` notebook provides an interactive environment for exploring the AgentBench data and jolt detection results. It includes:
1. Data loading and preprocessing
2. Jolt detection with detailed metrics
3. Publication-ready visualizations
4. Additional exploratory analyses

## Usage

```bash
# Generate synthetic data and run the analysis with default parameters
python run_agentbench_analysis.py

# Customize the synthetic data generation
python run_agentbench_analysis.py --start-date 2024-01-01 --num-months 18 --jolt-month 9 --jolt-magnitude 15.0 --noise-std 1.5

# Generate data without a jolt (for control comparison)
python run_agentbench_analysis.py --jolt-month -1
```

## Requirements

- Python 3.8+
- NumPy
- SciPy
- Pandas
- Matplotlib
- Seaborn
- Jupyter (for running notebooks)

## Integration with Manuscript

The results from this analysis are used in the Jolting Technologies manuscript to demonstrate the application of jolt detection methodology to AI agent performance data. The figures and tables generated by this code are directly referenced in the paper.

## License

MIT License

Copyright (c) 2025 Anonymous Authors

See the LICENSE file in the root directory for full license details.
