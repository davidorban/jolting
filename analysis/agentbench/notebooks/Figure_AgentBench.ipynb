{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgentBench Jolt Analysis Visualization\n",
    "\n",
    "This notebook visualizes the results of the AgentBench jolt detection analysis. It loads the synthetic AgentBench data, processes it, and creates publication-ready figures showing the performance trajectory and detected jolts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add parent directory to path to import our modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import our modules\n",
    "from agentbench_jolt.analyzer import (\n",
    "    preprocess_agentbench_data,\n",
    "    detect_agentbench_jolt,\n",
    "    plot_agentbench_jolt\n",
    ")\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data\n",
    "\n",
    "First, we'll load the synthetic AgentBench data and preprocess it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 7, saw 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m data_path = \u001b[33m\"\u001b[39m\u001b[33m../data/synthetic_agentbench_data.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded data with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m entries\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnique dates: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].nunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 1 fields in line 7, saw 8\n"
     ]
    }
   ],
   "source": [
    "# Load synthetic data\n",
    "data_path = \"../data/synthetic_agentbench_data.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Loaded data with {len(df)} entries\")\n",
    "    print(f\"Unique dates: {df['date'].nunique()}\")\n",
    "    print(f\"Unique models: {df['model'].nunique()}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    df.head()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Data file not found: {data_path}\")\n",
    "    print(\"Please run the run_agentbench_analysis.py script first to generate the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "processed_df = preprocess_agentbench_data(\n",
    "    df,\n",
    "    metric='median_score',\n",
    "    aggregation='max'\n",
    ")\n",
    "\n",
    "# Display preprocessed data\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Jolts\n",
    "\n",
    "Now we'll apply the jolt detection algorithm to identify super-exponential acceleration in the AgentBench performance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect jolt\n",
    "jolt_detected, jolt_info, derivs = detect_agentbench_jolt(\n",
    "    processed_df,\n",
    "    hybrid_final_threshold=0.6,\n",
    "    hybrid_peak_norm_factor=15.0,\n",
    "    hybrid_duration_norm_multiplier=2.0\n",
    ")\n",
    "\n",
    "print(f\"Jolt detected: {jolt_detected}\")\n",
    "if jolt_detected:\n",
    "    print(f\"Jolt date: {jolt_info.get('jolt_date', 'Unknown')}\")\n",
    "    print(f\"Jolt score: {jolt_info.get('score', 0):.2f}\")\n",
    "    print(f\"Peak score component: {jolt_info.get('components', {}).get('peak_score', 0):.2f}\")\n",
    "    print(f\"Pattern score component: {jolt_info.get('components', {}).get('pattern_score', 0):.2f}\")\n",
    "    print(f\"Duration score component: {jolt_info.get('components', {}).get('duration_score', 0):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's create publication-ready visualizations of the AgentBench performance trajectory and the detected jolt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main visualization\n",
    "fig = plot_agentbench_jolt(\n",
    "    processed_df, \n",
    "    derivs, \n",
    "    jolt_info,\n",
    "    title=\"AgentBench Performance Jolt Analysis (Synthetic Data)\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Additional Visualizations\n",
    "\n",
    "Let's create some additional visualizations to explore the data further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Convert date to datetime if it's not already\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd.api.types.is_datetime64_dtype(\u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m      6\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Get the top 5 models by final performance\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the performance of all models over time\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Convert date to datetime if it's not already\n",
    "if not pd.api.types.is_datetime64_dtype(df['date']):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Get the top 5 models by final performance\n",
    "final_date = df['date'].max()\n",
    "top_models = df[df['date'] == final_date].sort_values('median_score', ascending=False)['model'].head(5).tolist()\n",
    "\n",
    "# Plot the top models\n",
    "for model in top_models:\n",
    "    model_data = df[df['model'] == model].sort_values('date')\n",
    "    plt.plot(model_data['date'], model_data['median_score'], marker='o', linewidth=2, label=model)\n",
    "\n",
    "# Plot the maximum performance for each date\n",
    "max_by_date = df.groupby('date')['median_score'].max().reset_index()\n",
    "plt.plot(max_by_date['date'], max_by_date['median_score'], color='black', linewidth=3, \n",
    "         linestyle='--', label='Maximum Performance')\n",
    "\n",
    "# Add jolt marker if detected\n",
    "if jolt_detected and 'jolt_date' in jolt_info:\n",
    "    jolt_date = datetime.strptime(jolt_info['jolt_date'], '%Y-%m-%d')\n",
    "    jolt_y = max_by_date[max_by_date['date'] == jolt_date]['median_score'].values\n",
    "    if len(jolt_y) > 0:\n",
    "        plt.axvline(x=jolt_date, color='red', linestyle='--', alpha=0.7, label='Jolt Point')\n",
    "        plt.scatter([jolt_date], [jolt_y[0]], color='red', s=150, zorder=5)\n",
    "\n",
    "plt.title('Top 5 Models Performance Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Median Score', fontsize=14)\n",
    "plt.legend(title='Model', title_fontsize=12, fontsize=10, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Extract month from date\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].dt.strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Create violin plot\u001b[39;00m\n\u001b[32m      8\u001b[39m sns.violinplot(x=\u001b[33m'\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m'\u001b[39m, y=\u001b[33m'\u001b[39m\u001b[33mmedian_score\u001b[39m\u001b[33m'\u001b[39m, data=df, inner=\u001b[33m'\u001b[39m\u001b[33mquartile\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of performance scores by month\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Extract month from date\n",
    "df['month'] = df['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Create violin plot\n",
    "sns.violinplot(x='month', y='median_score', data=df, inner='quartile')\n",
    "\n",
    "# Add jolt marker if detected\n",
    "if jolt_detected and 'jolt_date' in jolt_info:\n",
    "    jolt_date = datetime.strptime(jolt_info['jolt_date'], '%Y-%m-%d')\n",
    "    jolt_month = jolt_date.strftime('%Y-%m')\n",
    "    plt.axvline(x=df['month'].unique().tolist().index(jolt_month), color='red', \n",
    "                linestyle='--', alpha=0.7, label='Jolt Month')\n",
    "\n",
    "plt.title('Distribution of Model Performance by Month', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.ylabel('Median Score', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m task_names = [\u001b[33m'\u001b[39m\u001b[33mOperating System\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDatabase\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mKnowledge Graph\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWeb Browsing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCoding\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (col, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(task_columns, task_names)):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     max_by_date = \u001b[43mdf\u001b[49m.groupby(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m)[col].max().reset_index()\n\u001b[32m     10\u001b[39m     plt.plot(max_by_date[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m], max_by_date[col], marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m, linewidth=\u001b[32m2\u001b[39m, label=name)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Add jolt marker if detected\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the task-specific performance over time\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Get the maximum performance for each task by date\n",
    "task_columns = ['os_score', 'db_score', 'kg_score', 'web_score', 'code_score']\n",
    "task_names = ['Operating System', 'Database', 'Knowledge Graph', 'Web Browsing', 'Coding']\n",
    "\n",
    "for i, (col, name) in enumerate(zip(task_columns, task_names)):\n",
    "    max_by_date = df.groupby('date')[col].max().reset_index()\n",
    "    plt.plot(max_by_date['date'], max_by_date[col], marker='o', linewidth=2, label=name)\n",
    "\n",
    "# Add jolt marker if detected\n",
    "if jolt_detected and 'jolt_date' in jolt_info:\n",
    "    jolt_date = datetime.strptime(jolt_info['jolt_date'], '%Y-%m-%d')\n",
    "    plt.axvline(x=jolt_date, color='red', linestyle='--', alpha=0.7, label='Jolt Point')\n",
    "\n",
    "plt.title('Maximum Task-Specific Performance Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Score', fontsize=14)\n",
    "plt.legend(title='Task', title_fontsize=12, fontsize=10, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Finally, let's save our visualizations and results for inclusion in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33m../results/figures\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Save the main visualization\u001b[39;00m\n\u001b[32m      5\u001b[39m fig = plot_agentbench_jolt(\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mprocessed_df\u001b[49m, \n\u001b[32m      7\u001b[39m     derivs, \n\u001b[32m      8\u001b[39m     jolt_info,\n\u001b[32m      9\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mAgentBench Performance Jolt Analysis\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     save_path=\u001b[33m\"\u001b[39m\u001b[33m../results/figures/agentbench_jolt_analysis.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResults saved to ../results/figures/agentbench_jolt_analysis.png\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'processed_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Create results directory if it doesn't exist\n",
    "os.makedirs(\"../results/figures\", exist_ok=True)\n",
    "\n",
    "# Save the main visualization\n",
    "fig = plot_agentbench_jolt(\n",
    "    processed_df, \n",
    "    derivs, \n",
    "    jolt_info,\n",
    "    title=\"AgentBench Performance Jolt Analysis\",\n",
    "    save_path=\"../results/figures/agentbench_jolt_analysis.png\"\n",
    ")\n",
    "\n",
    "print(\"Results saved to ../results/figures/agentbench_jolt_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This analysis demonstrates the application of our jolt detection methodology to AgentBench performance data. The results show that we can effectively identify periods of super-exponential acceleration in AI agent capabilities, which has important implications for understanding the pace of AI progress and potential governance challenges.\n",
    "\n",
    "The synthetic data used in this analysis serves as a placeholder until historical AgentBench data becomes available. The same methodology can be applied to real data when it is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
